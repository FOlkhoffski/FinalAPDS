---
title: 'Группа 3. Предсказание уровня GPA студентов'
author: 'Гасанова Алина, Кинаш Варвара, Ольховский Феликс, Райченко Софья, Созонова Евгения'
output: 
  html_document:
    code_folding: hide
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(pander)
library(DT)
library(caret)
library(tidyr)
library(corrplot)
library(dplyr)
library(clustMixType)
library(ggplot2)
library(umap)
library(dplyr)
library(skimr)
library(readr)
library(car)
library(caret)
library(xgboost)
library(Metrics)
library(readxl)
```

### Предобработка данных

```{r}
data = read_csv("student_lifestyle.csv", 
                col_types = cols(
                  Stress_Level = col_character(),
                  Student_ID = col_integer(),
                  .default = col_double()
                ))
```

```{r}
skim(data)

head(data)
```

Закодируем переменную Stress_Level в числовой формат в переменную Stress_Level_num, чтобы сохранить порядок и градацию стресса.

```{r}
data = data %>%
  mutate(Stress_Level_num = case_when(
    Stress_Level == "Low"    ~ 0,
    Stress_Level == "Moderate" ~ 1,
    Stress_Level == "High"   ~ 2,
    TRUE ~ NA_real_
  )) %>%
  select(-Stress_Level, -Student_ID) #удалим переменную Stress_Level и Student_ID

data = data %>%
  relocate(GPA, .after = last_col())  #переместим GPA в конец для удобства
```

Масштабируем целевую переменную GPA в шкалу оценивания от 0 до 10, как это принято в НИУ ВШЭ. Изначальная шкала была представлена в американском формате от 0 до 4

```{r}
data$GPA = data$GPA * 2.5
head(data)
```

```{r}
skim(data)
```

Пропусков в данных нет, выбросов тоже.

Посмотрим на зависимость переменных друг от друга:

```{r}
cor_matrix = cor(data)
heatmap(
  cor_matrix,
  symm = TRUE,
  cexRow = 0.7,
  cexCol = 0.7,
  margins = c(8, 8)
)
```

По построенной матрице видно, что сильнее всего с целевой переменной коррелирует уровень стресса и количество часов, посвященных учебе. Также именно эти переменные создают проблему Мультиколлинеарности.

### Линейная регрессия

Для начала перекодируем переменную уровня стресса в факторную и поделим выборку на тестовую и тренировочную.

```{r}
data$Stress_Level = factor(data$Stress_Level_num, levels = c(0, 1, 2), ordered = TRUE)
data = data %>% select(-Stress_Level_num)

set.seed(100)
test.ind = createDataPartition(data$GPA, p = 0.3, list = FALSE)
test = data[test.ind, ]
train = data[-test.ind, ]
```

Построим модель со всеми предикторами

```{r}
model_1 = lm(GPA ~ ., data = train)
summary(model_1) %>% pander()
```

```{r}
alias(model_1)
```

Из модели автоматически была исключена переменная Physical_Activity_Hours_Per_Day, поскольку для нее невозможно было рассчитать коэффициент. Произошло это из за того, что все переменные, показывающие количество часов, в сумме дают 24 часа, а значит одну можно выразить через другие. Отсюда и появляется сильная линейная зависимость между предикторами и, как следствие, невозможность высчитать коэффициент.

Попробуем построить помимо этой модели еще несколько, в каждой новой будем исключать переменную с Hours, которую ранее не убирали. После выявим наилучшую модель по метрикам RMSE, AIC, BIC.

```{r}
vars = c('Study_Hours_Per_Day', 'Extracurricular_Hours_Per_Day',
         'Sleep_Hours_Per_Day','Social_Hours_Per_Day', 'Physical_Activity_Hours_Per_Day')
res = data.frame(
  Excluded = character(),
  RMSE = numeric(),
  AIC = numeric(),
  BIC = numeric())

for (v in vars) {
  predictors = setdiff(vars, v)
  formula = as.formula(
    paste("GPA ~", paste(c(predictors, "Stress_Level"), collapse = " + "))
  )
  
  model = lm(formula, data = train)
  pred = predict(model, newdata = test)
  rmse = mean((test$GPA - pred)^2) %>% sqrt()
  aic = AIC(model)
  bic = BIC(model)
  
  res = rbind(res, data.frame(
    Excluded = v,
    RMSE = rmse,
    AIC = aic,
    BIC = bic
  ))
}

res %>% pander()
```

По полученной таблице можно сделать вывод, что без разницы какую переменную удалять, при отсутствии любого из 5 часовых предикторов предсказательная способность одинаковая.

Меньше всего с GPA коррелирует Physical_Activity_Hours_Per_Day, поэтому ее и уберем. А также построим модели где помимо уже исключенной переменной попробуем убрать еще одну, и выберем оптимальную.

```{r}
vars = c('Study_Hours_Per_Day', 'Extracurricular_Hours_Per_Day',
         'Sleep_Hours_Per_Day','Social_Hours_Per_Day', 'Stress_Level')
res = data.frame(
  Excluded = character(),
  RMSE = numeric(),
  AIC = numeric(),
  BIC = numeric())

for (v in vars) {
  predictors = setdiff(vars, v)
  formula = as.formula(
    paste("GPA ~", paste(predictors, collapse = " + "))
  )
  
  model = lm(formula, data = train)
  pred = predict(model, newdata = test)
  rmse = mean((test$GPA - pred)^2) %>% sqrt()
  aic = AIC(model)
  bic = BIC(model)
  
  res = rbind(res, data.frame(
    Excluded = v,
    RMSE = rmse,
    AIC = aic,
    BIC = bic
  ))
}

res %>% arrange(RMSE) %>% pander()
```

Наименьшее RMSE получилось при исключении переменной Social_Hours_Per_Day, значения критерия Акаике и Шварца не наименьшие, но мы прощаем это, поскольку нам важнее качество предсказания. При этом эти значения не сильно меньше тех, которые были у модели только без переменной Physical_Activity_Hours_Per_Day. Попробуем исключить еще переменную.

```{r}
vars = c('Study_Hours_Per_Day', 'Extracurricular_Hours_Per_Day',
         'Sleep_Hours_Per_Day', 'Stress_Level')
res = data.frame(
  Excluded = character(),
  RMSE = numeric(),
  AIC = numeric(),
  BIC = numeric())

for (v in vars) {
  predictors = setdiff(vars, v)
  formula = as.formula(
    paste("GPA ~", paste(predictors, collapse = " + "))
  )
  
  model = lm(formula, data = train)
  pred = predict(model, newdata = test)
  rmse = mean((test$GPA - pred)^2) %>% sqrt()
  aic = AIC(model)
  bic = BIC(model)
  
  res = rbind(res, data.frame(
    Excluded = v,
    RMSE = rmse,
    AIC = aic,
    BIC = bic
  ))
}

res %>% arrange(RMSE) %>% pander()
```

Значения RMSE поднялись по сравнению с результатами после прошлых итераций, так что остановимся на модели с исключенными Social_Hours_Per_Day и Physical_Activity_Hours_Per_Day. Рассмотрим выбранную модель поближе.

```{r}
model = lm(GPA ~ Study_Hours_Per_Day + Extracurricular_Hours_Per_Day +
         Sleep_Hours_Per_Day + Stress_Level, data = train)
model %>% summary() %>% pander()
```

У построенной модели значимы на 10% уровне только 3 коэффициента, поэтому интерпретировать будем только их. При отсутствии влияния всех предикторов среднее значение GPA составляет 5 из 10. Количество учебных часов в день влияет сильнее всего, каждый час, посвященный учебе, повышает средний балл на 0,38. Каждый час, посвященный внеклассным занятиям, снижает GPA на 0,02. Построенная модель способна обьяснить 54% вариаций зависимой переменной.

### Кластеризация
#### K-prototypes

Начнем со стандартизации непрерывных переменных и удалением переменной GPA.

```{r, warning=FALSE}
data_scaled = scale(data %>% select(-c(GPA, Stress_Level))) %>% as.data.frame()
data_scaled$Stress_Level = data$Stress_Level
```

Определим наилучшее число кластеров.

```{r, results='hide'}
clust = numeric()
for (k in 2:10) {
  set.seed(5)
  mod = kproto(data_scaled, k)
  clust[k] = mod$tot.withinss}
```
```{r}

plot(2:10, clust[2:10], type = "b", pch = 19,
     xlab = "Число кластеров", ylab = "Total within-cluster distance",
     main = "Зависимость WCD от числа кластеров")
```

По методу локтя оптимальное число кластеров получилось равным 3. Распределим наблюдения по кластерам с помощью kprototypes, а после построим визуализацию с помощью umap.

```{r, results='hide'}
kprot = kproto(data_scaled, k = 3)
data$Cluster = as.factor(kprot$cluster)
```

```{r}
data_numeric = data_scaled %>% mutate_if(is.factor, as.numeric)

set.seed(5)
umap = umap(data_numeric)
data_umap = data.frame(umap$layout, cluster = as.factor(data$Cluster))

ggplot(data_umap, aes(x = X1, y = X2, color = cluster)) +
  geom_point(alpha = 0.7, size = 2) +
  labs(title = "3 кластера на UMAP") +
  theme_minimal()
```

Группы выделяются странно, нет "чистых" облаков. Попробуем 4 кластера.

```{r, results='hide'}
kprot_4 = kproto(data_scaled, k = 4)
data$Cluster_4 = as.factor(kprot_4$cluster)
```
```{r}
set.seed(5)
data_umap_4 = data.frame(umap$layout, cluster = as.factor(data$Cluster_4))

ggplot(data_umap_4, aes(x = X1, y = X2, color = cluster)) +
  geom_point(alpha = 0.7, size = 2) +
  labs(title = "4 кластера на проекции UMAP") +
  theme_minimal()
```

Визуально лучше не стало, наблюдения все еще сильно перемешаны. Попробуем 2 кластера.

```{r, results='hide'}
kprot_2 = kproto(data_scaled, k = 2)
data$Cluster_2 = as.factor(kprot_2$cluster)
```
```{r}
set.seed(5)
data_umap_2 = data.frame(umap$layout, cluster = as.factor(data$Cluster_2))

ggplot(data_umap_2, aes(x = X1, y = X2, color = cluster)) +
  geom_point(alpha = 0.7, size = 2) +
  labs(title = " 2 кластера на проекции UMAP") +
  theme_minimal()
```

Двух кластеров не достаточно для хорошего разбиения наших наблюдений. Остановимся на 3 кластерах, так как мы предполагаем, что GPA будет разбиваться на три группы: удовлетворительно, хорошо и отлично (уровней GPA, соответствующих оценке ниже 4 по 10-ти балльной шкале, у нас нет в наблюдениях). Проверим различаются ли средние значения GPA по кластерам с помощью теста ANOVA, но для начала проверим нормальность распределения и равенство дисперсий между кластерами.

```{r, warning=FALSE}
by(data$GPA, data$Cluster, shapiro.test) %>% pander()
```

Для всех кластеров нулевая гипотеза о соответствии нормальному закону подтверждается.

```{r}
bartlett.test(GPA ~ Cluster, data = data) %>% pander()
```

Полученное p-value очень мало, дисперсии кластеров существенно различаются между собой, мы не можем применить тест ANOVA. Проверим средние значения с помощью непараметрического теста Welch ANOVA.

```{r}
oneway.test(GPA ~ Cluster, data = data) %>% pander()
```

P-value сильно меньше 1% уровня значимости, это значит, что хотя бы одна группа значимо отличается от остальных. Посмотрим на медианные значения.

```{r}
data %>% group_by(Cluster) %>% summarise(median_GPA = median(GPA)) %>% pander()
```

Медианные значения GPA первого и третьего кластера различаются на один балл, второй же кластер не сильно выделяется.

Построим боксплоты для визуального определения различий между кластерами.

## {.tabset}
### GPA
```{r}
ggplot(data, aes(x = Cluster, y = GPA, fill = Cluster)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение GPA по кластерам",
       x = "Кластер", y = "GPA") +
  theme_minimal()
```

### Study Hours
```{r}
ggplot(data, aes(x = Cluster, y = Study_Hours_Per_Day, fill = Cluster)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Study Hours по кластерам",
       x = "Кластер", y = "Study Hours") +
  theme_minimal()
```

### Extracurricular_Hours
```{r}
ggplot(data, aes(x = Cluster, y = Extracurricular_Hours_Per_Day,
                 fill = Cluster)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Extracurricular Hours по кластерам",
       x = "Кластер", y = "Extracurricular Hours") +
  theme_minimal()
```

### Sleep Hours
```{r}
ggplot(data, aes(x = Cluster, y = Sleep_Hours_Per_Day,
                 fill = Cluster)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Sleep Hours по кластерам",
       x = "Кластер", y = "Sleep Hours") +
  theme_minimal()
```

### Social Hours
```{r}
ggplot(data, aes(x = Cluster, y = Social_Hours_Per_Day,
                 fill = Cluster)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Social Hours по кластерам",
       x = "Кластер", y = "Social Hours") +
  theme_minimal()
```

### Physical Activity Hours
```{r}
ggplot(data, aes(x = Cluster, y = Physical_Activity_Hours_Per_Day,
                 fill = Cluster)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Physical Activity Hours по кластерам",
       x = "Кластер", y = "Physical Activity Hours") +
  theme_minimal()
```

### Stress Level
```{r}
data %>%
  group_by(Cluster, Stress_Level) %>%
  summarise(n = n(), .groups = "drop") %>%
  group_by(Cluster) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = Cluster, y = prop, fill = as.factor(Stress_Level))) +
  geom_col(position = "fill") + 
  scale_fill_manual(values = c("0" = "#87CEFA", 
                             "1" = "#1E90FF", 
                             "2" = "navyblue")) +
  labs(title = "Доли уровней стресса внутри каждого кластера",
       x = "Кластер", y = "Доля",
       fill = "Уровень стресса") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal()
```

## {.unnumbered}

Таким образом, несмотря на то, что статистически выделенные кластеры хорошие, на практике они не добавят нам полезной информации. Если различия между 1 и 2 кластром еще можно как то описать (и то разница в 1 балл по 10-ти бальной шкале не очень информативно), то различия между 2 и 3 кластером минимальны.

#### K-means

Попробуем удалить Stress_Level и использовать kmeans. Сначала построим 3 кластера.

```{r}
set.seed(5)
kmeans_3 = data_scaled %>% select(-Stress_Level) %>% kmeans(, centers = 3, nstart = 25)

data$kmeans_cluster = as.factor(kmeans_3$cluster)
```

```{r}
data_numeric_kmeans = data_scaled %>% select(-Stress_Level)

set.seed(5)
umap_kmeans = umap(data_numeric_kmeans)

data_umap_kmeans = data.frame(umap_kmeans$layout, cluster = data$kmeans_cluster)

ggplot(data_umap_kmeans, aes(x = X1, y = X2, color = cluster)) +
  geom_point(alpha = 0.7, size = 2) +
  labs(title = "3 кластера на UMAP для kmeans") +
  theme_minimal()
```

Данные неплохо разбились на 3 кластера, но все же некоторые наблюдения попадают в чужие облака, построим 4 кластера.

```{r}
set.seed(5)
kmeans_4 = data_scaled %>% select(-Stress_Level) %>% kmeans(, centers = 4, nstart = 25)

data$kmeans_cluster_4 = as.factor(kmeans_4$cluster)
```

```{r}
set.seed(5)
data_umap_kmeans <- data.frame(umap_kmeans$layout, cluster = data$kmeans_cluster_4)

ggplot(data_umap_kmeans, aes(x = X1, y = X2, color = cluster)) +
  geom_point(alpha = 0.7, size = 2) +
  labs(title = "4 кластера на UMAP для kmeans") +
  theme_minimal()
```

Добавление еще одного кластера не помогло, построим 2 кластера.

```{r}
set.seed(5)
kmeans_2 = data_scaled %>% select(-Stress_Level) %>% kmeans(, centers = 2, nstart = 25)

data$kmeans_cluster_2 = as.factor(kmeans_2$cluster)
```

```{r}
set.seed(5)
data_umap_kmeans <- data.frame(umap_kmeans$layout, cluster = data$kmeans_cluster_2)

ggplot(data_umap_kmeans, aes(x = X1, y = X2, color = cluster)) +
  geom_point(alpha = 0.7, size = 2) +
  labs(title = "2 кластера на UMAP для kmeans") +
  theme_minimal()
```

Два кластера так же, как и три, дают хорошее разбиение, но мы решили остановиться на трех, поскольку такое количество групп, на наш взгляд, логичнее применить к уровням GPA.

Посчитаем медианные значения GPA по кластерам.

```{r}
data %>% group_by(kmeans_cluster) %>% summarise(median_GPA = median(GPA)) %>% pander()
```

Медианные значения вышли очень близкими друг к другу. Проверим данные по GPA по кластерам на нормальность.

```{r, warning=FALSE}
by(data$GPA, data$kmeans_cluster, shapiro.test) %>% pander()
```

Судя по результатам теста, только для первого и третьего кластера гипотеза о нормальности распределения наблюдений не отвергается на уровне значимости 5%. Во втором кластере данные распределены не по нормальному закону.

Проверим сходство дисперсий.

```{r}
leveneTest(GPA ~ kmeans_cluster, data = data) %>% pander()
```

Судя по результатам теста, нет статистически значимых различий в дисперсиях кластеров. Можем применить тест ANOVA, который устойчив к небольшим отклонениям от нормальности.

```{r}
aov(GPA ~ kmeans_cluster, data = data) %>% summary() %>% pander()
```

Резултаты дисперсионного анализа показывают, что различия между средниями значениями GPA по кластерам статистически значимы, хотя бы один кластер отличается.

Построим по каждой переменной ящик с усами для выявления возможных различий между кластерами.

## {.tabset}
### GPA

```{r}
ggplot(data, aes(x = kmeans_cluster, y = GPA, fill = kmeans_cluster)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение GPA по кластерам",
       x = "Кластер", y = "GPA") +
  theme_minimal()
```

### Study Hours
```{r}
ggplot(data, aes(x = kmeans_cluster, y = Study_Hours_Per_Day, fill = kmeans_cluster)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Study Hours по кластерам",
       x = "Кластер", y = "Study Hours") +
  theme_minimal()
```

### Extracurricular_Hours
```{r}
ggplot(data, aes(x = kmeans_cluster, y = Extracurricular_Hours_Per_Day,
                 fill = kmeans_cluster)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Extracurricular Hours по кластерам",
       x = "Кластер", y = "Extracurricular Hours") +
  theme_minimal()
```

### Sleep Hours
```{r}
ggplot(data, aes(x = kmeans_cluster, y = Sleep_Hours_Per_Day,
                 fill = kmeans_cluster)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Sleep Hours по кластерам",
       x = "Кластер", y = "Sleep Hours") +
  theme_minimal()
```

### Social Hours
```{r}
ggplot(data, aes(x = kmeans_cluster, y = Social_Hours_Per_Day,
                 fill = kmeans_cluster)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Social Hours по кластерам",
       x = "Кластер", y = "Social Hours") +
  theme_minimal()
```

### Physical Activity Hours
```{r}
ggplot(data, aes(x = kmeans_cluster, y = Physical_Activity_Hours_Per_Day,
                 fill = kmeans_cluster)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Physical Activity Hours по кластерам",
       x = "Кластер", y = "Physical Activity Hours") +
  theme_minimal()
```

## {.unnumbered}

Получается, что кластеризация без учета переменной Stress_Level тоже дала довольно схожие группы.

Обе кластеризации могли не дать ярких результатов и различий по уровням GPA. Мы не будем использовать результаты ни по одному из методов в наших предсказательных моделях, поскольку они не добавляют никакой новой информации и плохо показывают ненаблюдаемые индивидуальные различия между группами.

Результаты кластеризации могли не удовлетворить наши представления о возможных группах в силу того, что 75% нашей выборким имеют средний балл выше 7.25. То есть у нас вся выборка состоит из отличников, что будет являться одним большим кластером.

#### Самостоятельно выделенные группы

Однако нам все еще интересно посмотреть обладают ли студенты разных групп, выделенных по высоте оценке, какими то отличиями. Попробуем самостоятельно определить группы по уровню GPA и посмотреть имеются ли какие то характерные отличия в этих группах. Выделять будем по вышкинской системе, то есть, 4-5 = удовлетворительно, 6-7 = хорошо, 8-10 = отлично.

```{r}
data = data %>% mutate(group = case_when(
  GPA >= 4 & GPA < 6 ~ 1,
  GPA >= 6 & GPA < 7 ~ 2,
  GPA >= 7 & GPA <= 10 ~ 3
))
```

```{r}
table(data$group) %>% prop.table() %>% pander()
```

Группы получились несбалансированными, но поскольку у нас нет цели применить их в предсказательной модели, а нам интересно посмотреть на различия между группами, мы простим это. 

## {.tabset}
### GPA
```{r}
data$group <- factor(data$group, levels = c(1, 2, 3),
                     labels = c("Low GPA", "Mid GPA", "High GPA"))

ggplot(data, aes(x = group, y = GPA, fill = group)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение GPA по выделенным группам",
       x = "Группа", y = "GPA") +
  theme_minimal()
```

### Study Hours
```{r}
ggplot(data, aes(x = group, y = Study_Hours_Per_Day, fill = group)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Study Hours по выделенным группам",
       x = "Группа", y = "Study Hours") +
  theme_minimal()
```

### Extracurricular_Hours
```{r}
ggplot(data, aes(x = group, y = Extracurricular_Hours_Per_Day,
                 fill = group)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Extracurricular Hours по выделенным группам",
       x = "Группа", y = "Extracurricular Hours") +
  theme_minimal()
```

### Sleep Hours
```{r}
ggplot(data, aes(x = group, y = Sleep_Hours_Per_Day,
                 fill = group)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Sleep Hours по выделенным группам",
       x = "Группа", y = "Sleep Hours") +
  theme_minimal()
```

### Social Hours
```{r}
ggplot(data, aes(x = group, y = Social_Hours_Per_Day,
                 fill = group)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Social Hours по выделенным группам",
       x = "Группа", y = "Social Hours") +
  theme_minimal()
```

### Physical Activity Hours
```{r}
ggplot(data, aes(x = group, y = Physical_Activity_Hours_Per_Day,
                 fill = group)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Распределение Physical Activity Hours по выделенным группам",
       x = "Группа", y = "Physical Activity Hours") +
  theme_minimal()
```

### Stress Level
```{r}
data %>%
  group_by(group, Stress_Level) %>%
  summarise(n = n(), .groups = "drop") %>%
  group_by(group) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(x = group, y = prop, fill = as.factor(Stress_Level))) +
  geom_col(position = "fill") + 
  scale_fill_manual(values = c("0" = "#87CEFA", 
                             "1" = "#1E90FF", 
                             "2" = "navyblue")) +
  labs(title = "Доли уровней стресса внутри каждой выделенной группы",
       x = "Группа", y = "Доля",
       fill = "Уровень стресса") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal()
```

## {.unnumbered}

Студенты с высоким уровнем GPA уделяют учёбе больше времени, чем все остальные. Даже аномальное значение в группе с низким GPA не достигает уровня их первого квантиля.

Количество внеурочных часов у студентов с высоким или средним GPA имеет больший разброс, чем у тех, чей GPA можно назвать низким.

Половина опрошенных студентов в каждой группе спит от 7 до 8 часов. Однако у студентов со средним или высоким GPA продолжительность сна варьируется от 5 до 10 часов, в то время как у студентов с низким GPA этот диапазон составляет от 5,25 до почти 9 часов.

Время на внеурочное общение примерно одинаково для всех трёх групп.

Чем выше уровень GPA, тем меньше времени уделяется спортивной активности.

Что касается уровня стресса, то чем выше GPA, тем больше доля студентов, испытывающих сильное нервное напряжение. При этом доля тех, чей стресс можно охарактеризовать как умеренный, примерно одинакова в группах со средним и высоким GPA.

Также стоит отметить, что из-за малого объёма первой группы такие характеристики, как внеурочные часы, часы сна и время, проведённое не за учебой, скорее всего, будут примерно одинаковы для всех трёх групп. Это перекликается с построенной ранее корреляционной матрицей, из которой видно, что с GPA слабо коррелируют все признаки, кроме уровня стресса и количества часов, посвящённых учёбе.

### Бустинг 

Настроим кросс-валидацию и начальные гиперпараметры для перебора
```{r, results='hide'}
ctrl <- trainControl(
  method = "cv",
  number = 5,
  verboseIter = TRUE
)

grid <- expand.grid(
  nrounds = c(50, 100, 150),
  max_depth = c(3, 6, 9),
  eta = c(0.01, 0.1, 0.3),
  gamma = c(0, 1),
  colsample_bytree = c(0.7),
  min_child_weight = c(1, 5),
  subsample = c(0.7)
)

xgb_model <- train(
  GPA ~ .,
  data = train,
  method = "xgbTree",
  trControl = ctrl,
  tuneGrid = grid,
  metric = "RMSE"
)
```


Посмотрим на гиперпараметры лучшей модели, которые подобрал алгоритм:
```{r}
pander(xgb_model$bestTune)
```

Теперь посмотрим на оценки качества модели:
```{r}
preds <- predict(xgb_model, newdata = test)

rmse_val <- rmse(test$GPA, preds)
mae_val <- mae(test$GPA, preds)
r2_val <- 1 - sum((test$GPA - preds)^2) / sum((test$GPA - mean(test$GPA))^2)

cat("Метрики модели после подбора:\n") %>% pander()
cat("RMSE:", round(rmse_val, 4), "\n") %>% pander()
cat("MAE :", round(mae_val, 4), "\n") %>% pander()
cat("R²  :", round(r2_val, 4), "\n") %>% pander()
```

Поскольку обе модели дают очень близкие значения RMSE, было принято решение отдать выбор модели пользователям. Мы включим обе модели в интерфейс.

### Тестирование моделей

Для тестирования мы использовали реальные данные, которые получили от наших друзей, одногруппников и знакомых. Данные собирались через гугл форму. Для тестирования нами были отобраны несколько примеров, которые в нашем понимании дают понимание качества предсказания моделей для разных уровеней GPA.

```{r}
surv = read_excel('/srv/store/students2023/sbraychenko_1/final_project/survey_results.xlsx', sheet = 'Лист1')
surv$Stress_Level = factor(surv$Stress_Level, levels = c(0, 1, 2), ordered = TRUE)
surv$ID = 1:nrow(surv)

datatable(surv, 
          rownames = FALSE,
          options = list(dom = 't', pageLength = 10)) %>%
  formatRound(columns = c(2,3), digits = 1)
```

#### Линейная регрессия

Начнем с тестирования обычной линейной регрессии.

```{r}
pred = predict(model, newdata = surv[ ,1:6]) %>% round(digits = 3)

results = data.frame(
  Predicted = pred,
  Real = surv$GPA
)
results$ID = 1:nrow(results)
datatable(results, 
          rownames = FALSE,
          options = list(dom = 't', pageLength = 10)) %>%
  formatRound(columns = c(2,3), digits = 1)
```

```{r}
long_results = pivot_longer(results,
                             cols = c("Predicted", "Real"),
                             names_to = "Type",
                             values_to = "GPA")

ggplot(long_results, aes(x = factor(ID), y = GPA, fill = Type)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("Real" = "orange", "Predicted" = "deeppink")) +
  labs(title = "Сравнение предсказанных и реальных значений GPA",
       x = "Номер ответа",
       y = "GPA",
       fill = "Тип значения") +
  theme_minimal()
```

Можно предположить, что с ростом GPA предсказания улучшается. Построим график, где будут отображены только ошибки.

```{r}
results$Error = abs(results$Real - results$Predicted)

ggplot(results, aes(x = ID, y = Error)) +
  geom_point(color = "deeppink", size = 3) +
  geom_line(color = "orange", linetype = "dashed") +
  geom_hline(yintercept = 0, color = "black", linetype = "dotted") +
  labs(title = "Ошибка предсказания GPA",
       y = "Ошибка") +
  theme_minimal()
```

Как мы видим по графику, нельзя сказать, что модель всегда отлично предсказывает выские значения GPA. Однако, ошибка при предсказании низких значений GPA стабильно не очень хорошая, модель ошибается примерно на полтора балла. Это может быть связано с тем, что в тренировочной выборке не хватило наблюдений со средним баллом ниже 7. Мы при подведении итогов кластеризации мы уже указывали на то, что большая часть выборки составляют отличники. 

Отсортируем датасет по величине ошибки и посмотрим, что может связывать такие плохие предсказания.

```{r}
error = results %>% select(ID, Error)
surv = surv %>% left_join(error, by = 'ID')

datatable(surv %>% arrange(Error), 
          rownames = FALSE,
          options = list(dom = 't', pageLength = 10)) %>%
  formatRound(columns = c(2,3), digits = 1)
```

На наш взгляд, единственное, что обьединяет эти данные, так это тот факт, что реальное значение GPA ниже 7. В будущем стоит собрать данные и дообучить модель.